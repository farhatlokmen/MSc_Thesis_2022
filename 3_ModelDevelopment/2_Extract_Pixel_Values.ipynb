{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir1 = r'G:\\CopernicusTurbidityLayers'\n",
    "subdir1 = os.path.join(maindir1,'masked')\n",
    "maindir2 = r'G:\\ReflectanceLayers'\n",
    "cases = ['withoutGF','withGF']\n",
    "for case in cases:\n",
    "    subdir2 = os.path.join(maindir2,case,'France')\n",
    "    maindir3= r'G:\\preparedInputData'\n",
    "    dates = os.listdir(subdir2)\n",
    "    tenDays = np.array([[0,0,0,0]])\n",
    "    for i in range(0,len(dates),4):                         \n",
    "        tenDays = np.r_[tenDays,[[dates[i+k] for k in range(4)]]] \n",
    "    tenDays = tenDays[1:]\n",
    "    for k in range(15):\n",
    "        file1 = os.listdir(subdir1)[k]\n",
    "        turImg = rio.open(os.path.join(subdir1,file1))\n",
    "        turArr = turImg.read()\n",
    "        myarray = turArr.copy()                          \n",
    "        for date in tenDays[k]:                              \n",
    "            subdir3 = os.path.join(subdir2,date)        \n",
    "            for layer in os.listdir(subdir3):                           \n",
    "                reflectanceArr = rio.open(os.path.join(subdir3,layer)).read()\n",
    "                myarray = np.append(myarray, reflectanceArr, axis=0)\n",
    "        outputdir = os.path.join(maindir3,case,'France', 'merged_'+file1)\n",
    "        with rio.open(outputdir,'w',driver='Gtiff', width=turImg.width, height=turImg.height, \n",
    "                            count=37,crs=turImg.crs,transform=turImg.transform, dtype='float32', nodata=9.96921e+36) as newImg:\n",
    "            for k in range(len(myarray)):\n",
    "                newImg.write(myarray[k,:,:], indexes=k+1)\n",
    "            newImg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir1 = r'G:\\preparedInputData'\n",
    "subdir1 = os.path.join(maindir1,'withoutGF')\n",
    "nb_none = 0\n",
    "nb_UP = 0\n",
    "nb_KP = 0\n",
    "for file1 in os.listdir(subdir1):\n",
    "    if file1.endswith('tiff'):\n",
    "        img = rio.open(os.path.join(subdir1,file1)) \n",
    "        arr = img.read()        \n",
    "        turLayer = arr[0]\n",
    "        for i in range(turLayer.shape[0]):\n",
    "            for j in range(turLayer.shape[1]):\n",
    "                if turLayer[i,j]>1e+36:\n",
    "                    nb_none+=1\n",
    "                elif turLayer[i,j]<0:\n",
    "                    nb_UP+=1\n",
    "                else:\n",
    "                    nb_KP+=1        \n",
    "        print(file1[7:15],'nb_none:',nb_none,'__','nb_UP:',nb_UP,'__','5% nb_KP:',int(nb_KP*0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixelValue(array,idx1,idx2,idx3):\n",
    "    return array[idx1,idx2,idx3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### without GF ### clear sky ###\n",
    "\n",
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "subdir1 = os.path.join(maindir1,'withoutGF','France')\n",
    "for file1 in os.listdir(subdir1):\n",
    "    if file1.endswith('tiff'):\n",
    "        img1 = rio.open(os.path.join(subdir1,file1)) # start by reading all layers\n",
    "        arr1 = img1.read()\n",
    "        for idx in range(arr1.shape[1]):\n",
    "            for idy in range(arr1.shape[2]):\n",
    "                if arr1[0,idx,idy] >= 1e+36:\n",
    "                    for n in range(1,arr1.shape[0]):\n",
    "                        arr1[n,idx,idy] = 9.96921e+36\n",
    "        indices = [i for i in range(1,36,9)]\n",
    "        nb_KP = []\n",
    "        for i in indices:\n",
    "            temp_copy = deepcopy(arr1[i])\n",
    "            temp_copy[temp_copy==-99]=9.96921e+36\n",
    "            nb_KP.append(len(np.argwhere(temp_copy<=1e+36).tolist()))        \n",
    "        df1 = pd.DataFrame({'indices':indices,'nb_KP':nb_KP})\n",
    "        df1.sort_values('nb_KP', inplace=True)  \n",
    "        df1.reset_index(drop=True, inplace=True) \n",
    "        for i in tqdm([0,1,2,3]): \n",
    "            name = 'Pixels_From_Best_'+str(4-i)+'_S2_'+file1[7:15]           \n",
    "            l = list(df1[i:]['indices'])   \n",
    "            arr1_temp = np.expand_dims(arr1[0], axis=0)\n",
    "            for k1 in l: \n",
    "                for k2 in range(k1,k1+9):\n",
    "                    arr1_temp = np.append(arr1_temp,np.expand_dims(arr1[k2], axis=0),axis=0)\n",
    "            list_coordKP = np.argwhere(arr1_temp[0,:,:]<1e+36).tolist()\n",
    "            list_KP_Values = list(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36])\n",
    "            m = int(np.min(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36]))\n",
    "            M = int(np.max(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36]))\n",
    "            list_boundary_values = []\n",
    "            for t in range(m,M,20):            \n",
    "                list_boundary_values.append(t)\n",
    "            if M not in list_boundary_values:\n",
    "                list_boundary_values.append(M+1)\n",
    "            list_names=['list'+str(i) for i in range(len(list_boundary_values)-1)]\n",
    "            groups_KP1 = {}\n",
    "            for list_name in list_names:\n",
    "                groups_KP1[list_name] = []\n",
    "            for _ in range(len(list_KP_Values)):              \n",
    "                for i in range(len(list_boundary_values)-1): \n",
    "                    if (list_KP_Values[_]>=list_boundary_values[i]) and (list_KP_Values[_]<list_boundary_values[i+1]):\n",
    "                        groups_KP1['list'+str(i)].append(list_coordKP[_])\n",
    "            n_KP_noGF = 0\n",
    "            for key in groups_KP1.keys():               \n",
    "                idX1_temp = []\n",
    "                idY1_temp = []\n",
    "                for i1 in range(len(groups_KP1[key])):\n",
    "                    x_temp, y_temp = groups_KP1[key][i1]\n",
    "                    vector = [arr1_temp[m, x_temp, y_temp] for m in range(len(arr1_temp))]\n",
    "                    missingData = vector.count(-99)   \n",
    "                    if missingData == 0:    \n",
    "                        idX1_temp.append(x_temp)\n",
    "                        idY1_temp.append(y_temp)                    \n",
    "                groups_KP1[key] = list(zip(idX1_temp, idY1_temp)) \n",
    "                n_KP_noGF+=len(list(zip(idX1_temp, idY1_temp)))       \n",
    "            if (0.05*n_KP_noGF) > 5001:\n",
    "                n1 = 0.05*n_KP_noGF  \n",
    "            else:\n",
    "                if n_KP_noGF > 5001:\n",
    "                    n1 = 5001\n",
    "                else:\n",
    "                    n1 = n_KP_noGF                    \n",
    "            idX1 = []\n",
    "            idY1 = []\n",
    "            for key in groups_KP1.keys():                \n",
    "                random.seed(4)\n",
    "                list_temp1 = random.sample(groups_KP1[key],len(groups_KP1[key])) \n",
    "                if n_KP_noGF > 0:\n",
    "                    percent = len(groups_KP1[key])/n_KP_noGF                            \n",
    "                    n2 = int(percent*n1)              \n",
    "                    if n2 > 0:\n",
    "                        for i1 in range(n2):\n",
    "                            x_temp1, y_temp1 = list_temp1[i1]  \n",
    "                            idX1.append(x_temp1)\n",
    "                            idY1.append(y_temp1)          \n",
    "            rows1 = ['L'+str(index) for index in range(len(arr1_temp))]\n",
    "            columns1 = [index for index in range(len(idX1))]\n",
    "            results1 = pd.DataFrame(index=rows1, columns=columns1)\n",
    "            data1 = [] \n",
    "            for idxLayer in range(len(arr1_temp)):\n",
    "                pixelValues = Parallel(n_jobs=-1)(delayed(getPixelValue)(arr1_temp,idxLayer,idX1[k],idY1[k]) for k in range(len(idX1)))\n",
    "                data1.append(pixelValues)\n",
    "            results1 = pd.DataFrame(data1, index=rows1, columns=columns1).T\n",
    "            results1.insert(loc=0, column='idx', value=idX1)   \n",
    "            results1.insert(loc=1, column='idy', value=idY1)\n",
    "            path1 = os.path.join(subdir1,file1[7:15])\n",
    "            os.makedirs(path1, exist_ok=True)\n",
    "            outputdir1 = os.path.join(path1, name+'.xlsx')\n",
    "            results1.to_excel(outputdir1, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with GF ### different amounts of gaps ###\n",
    "\n",
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "subdir0 = os.path.join(maindir1,'withoutGF','France')  \n",
    "subdir1 = os.path.join(maindir1,'withGF','France')\n",
    "for file1 in os.listdir(subdir1):\n",
    "    if file1.endswith('tiff'):\n",
    "        arr0 = rio.open(os.path.join(subdir0,file1)).read()\n",
    "        img1 = rio.open(os.path.join(subdir1,file1)) \n",
    "        arr1 = img1.read()\n",
    "        for idx in range(arr0.shape[1]):\n",
    "            for idy in range(arr0.shape[2]):\n",
    "                if arr0[0,idx,idy] >= 1e+36:\n",
    "                    for n in range(1,arr0.shape[0]):\n",
    "                        arr0[n,idx,idy] = 9.96921e+36\n",
    "        indices = [i for i in range(1,36,9)]\n",
    "        nb_KP = []\n",
    "        for i in indices:\n",
    "            temp_copy = deepcopy(arr0[i])\n",
    "            temp_copy[temp_copy==-99]=9.96921e+36\n",
    "            nb_KP.append(len(np.argwhere(temp_copy<=1e+36).tolist()))        \n",
    "        df1 = pd.DataFrame({'indices':indices,'nb_KP':nb_KP})\n",
    "        df1.sort_values('nb_KP', inplace=True)  \n",
    "        df1.reset_index(drop=True, inplace=True) \n",
    "        for i in tqdm([1,2,3]):\n",
    "            name = 'Pixels_From_Best_'+str(4-i)+'_S2_'+file1[7:15]           \n",
    "            l = list(df1[i:]['indices'])   \n",
    "            arr1_temp = np.expand_dims(arr1[0], axis=0)            \n",
    "            for k1 in l:\n",
    "                for k2 in range(k1,k1+9):\n",
    "                    arr1_temp = np.append(arr1_temp,np.expand_dims(arr1[k2], axis=0),axis=0) \n",
    "            list_coordKP = np.argwhere(arr1_temp[0,:,:]<1e+36).tolist()\n",
    "            list_KP_Values = list(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36])\n",
    "            m = int(np.min(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36]))\n",
    "            M = int(np.max(arr1_temp[0,:,:][arr1_temp[0,:,:]<1e+36]))\n",
    "            list_boundary_values = []\n",
    "            for t in range(m,M,20):            \n",
    "                list_boundary_values.append(t)\n",
    "            if M not in list_boundary_values:\n",
    "                list_boundary_values.append(M+1)\n",
    "            list_names=['list'+str(i) for i in range(len(list_boundary_values)-1)]\n",
    "            groups_KP1 = {}\n",
    "            for list_name in list_names:\n",
    "                groups_KP1[list_name] = []\n",
    "            for _ in range(len(list_KP_Values)):              \n",
    "                for i in range(len(list_boundary_values)-1): \n",
    "                    if (list_KP_Values[_]>=list_boundary_values[i]) and (list_KP_Values[_]<list_boundary_values[i+1]):\n",
    "                        groups_KP1['list'+str(i)].append(list_coordKP[_]) \n",
    "            n_KP_GF = 0 \n",
    "            for key in groups_KP1.keys():               \n",
    "                idX1_temp = []\n",
    "                idY1_temp = []\n",
    "                for i1 in range(len(groups_KP1[key])):\n",
    "                    x_temp, y_temp = groups_KP1[key][i1]\n",
    "                    vector = [arr1_temp[m, x_temp, y_temp] for m in range(len(arr1_temp))] \n",
    "                    missingData = vector.count(-99)                       \n",
    "                    if i==1: # best3\n",
    "                        MD = 19\n",
    "                    elif i==2 or i==3: \n",
    "                        MD = 10     \n",
    "                    if missingData < MD:    \n",
    "                        idX1_temp.append(x_temp)\n",
    "                        idY1_temp.append(y_temp)                 \n",
    "                groups_KP1[key] = list(zip(idX1_temp, idY1_temp)) \n",
    "                n_KP_GF+=len(list(zip(idX1_temp, idY1_temp)))       \n",
    "            if (0.05*n_KP_GF) > 5001:\n",
    "                n1 = 0.05*n_KP_GF  \n",
    "            else:\n",
    "                if n_KP_GF > 5001:\n",
    "                    n1 = 5001\n",
    "                else:\n",
    "                    n1 = n_KP_GF                    \n",
    "            idX1 = []\n",
    "            idY1 = []\n",
    "            for key in groups_KP1.keys():                \n",
    "                random.seed(4)\n",
    "                list_temp1 = random.sample(groups_KP1[key],len(groups_KP1[key])) \n",
    "                if n_KP_GF > 0:\n",
    "                    percent = len(groups_KP1[key])/n_KP_GF                           \n",
    "                    n2 = int(percent*n1)              \n",
    "                    if n2 > 0:\n",
    "                        for i1 in range(n2):\n",
    "                            x_temp1, y_temp1 = list_temp1[i1]   \n",
    "                            idX1.append(x_temp1)\n",
    "                            idY1.append(y_temp1)           \n",
    "            rows1 = ['L'+str(index) for index in range(len(arr1_temp))]\n",
    "            columns1 = [index for index in range(len(idX1))]\n",
    "            results1 = pd.DataFrame(index=rows1, columns=columns1)\n",
    "            data1 = [] \n",
    "            for idxLayer in range(len(arr1_temp)):\n",
    "                pixelValues = Parallel(n_jobs=-1)(delayed(getPixelValue)(arr1_temp,idxLayer,idX1[k],idY1[k]) for k in range(len(idX1)))\n",
    "                data1.append(pixelValues)\n",
    "            results1 = pd.DataFrame(data1, index=rows1, columns=columns1).T\n",
    "            results1.insert(loc=0, column='idx', value=idX1)   \n",
    "            results1.insert(loc=1, column='idy', value=idY1)  \n",
    "            path1 = os.path.join(subdir1,file1[7:15])\n",
    "            os.makedirs(path1, exist_ok=True)\n",
    "            outputdir1 = os.path.join(path1, name+'.xlsx')\n",
    "            results1.to_excel(outputdir1, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "gf_folders = ['withoutGF','withGF']\n",
    "GF = []\n",
    "Date = []\n",
    "S2 = []\n",
    "Samples = []\n",
    "for i in tqdm([0,1]):\n",
    "    gf_folder = gf_folders[i]\n",
    "    subdir1 = os.path.join(maindir1,gf_folder,'France')    \n",
    "    for file1 in os.listdir(subdir1):\n",
    "        if 'tiff' not in file1:\n",
    "            subdir2 = os.path.join(maindir1,gf_folder,'France',file1)\n",
    "            for file2 in os.listdir(subdir2):\n",
    "                excel_file = pd.read_excel(os.path.join(subdir1,file1,file2))\n",
    "                GF.append(gf_folder)\n",
    "                Date.append(file1)\n",
    "                S2.append(file2[12:18])\n",
    "                Samples.append(excel_file.shape[0])\n",
    "df = pd.DataFrame({'GF':GF, 'Date':Date, 'S2':S2, 'Samples':Samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir2 = os.path.join(maindir1,'summary.xlsx')\n",
    "df.to_excel(outputdir2, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
