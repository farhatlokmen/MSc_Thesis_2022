{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T04:24:25.362875Z",
     "start_time": "2022-01-16T04:24:21.280037Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(4)\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import rasterio as rio\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor as ANN\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.colors as colors\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T04:24:25.430130Z",
     "start_time": "2022-01-16T04:24:25.415111Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_random_seed(x):\n",
    "    tf.random.set_seed(x) # Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    np.random.seed(x)     # Set the `numpy` pseudo-random generator at a fixed value\n",
    "    random.seed(x)        # Set the `python` built-in pseudo-random generator at a fixed value      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T04:24:25.612869Z",
     "start_time": "2022-01-16T04:24:25.484062Z"
    }
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Reproducibility is a Problem when using parallel processing  (n_jobs = 1)#\n",
    "############################################################################ \n",
    "seed = 4\n",
    "set_random_seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:09:03.435942Z",
     "start_time": "2022-01-16T12:09:03.426961Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(learn_rate=0.01, units1=14,units2=12,activ_func1='sigmoid',activ_func2='sigmoid',activ_func3='sigmoid'):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, kernel_initializer='uniform', activation=activ_func1, input_shape=(Nfeatures,))) \n",
    "    model.add(Dense(units2, kernel_initializer='uniform', activation=activ_func2))                           \n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation=activ_func3))\n",
    "    optimizer = Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adam\")\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T15:46:15.423771Z",
     "start_time": "2022-01-16T12:09:10.353468Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [01:33<00:00,  6.23s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [56:39<00:00, 226.66s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 15/15 [2:38:48<00:00, 635.25s/it]\n"
     ]
    }
   ],
   "source": [
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "maindir2 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning'\n",
    "ml_models = ['KNN','RF','ANN']\n",
    "# gf_folders = ['withoutGF','withGF']\n",
    "gf_folders = ['withGF']\n",
    "scoring = {'mse':'neg_mean_squared_error', 'r2': 'r2'}\n",
    "\n",
    "Model = []\n",
    "GF = []\n",
    "DATE = []\n",
    "Nb_S2_used = []\n",
    "mse = []\n",
    "r2 = []\n",
    "        \n",
    "for ml_model in ml_models:    \n",
    "    for gf_folder in gf_folders:    \n",
    "        subdir1 = os.path.join(maindir1,gf_folder,'France')\n",
    "        files_temp = [fileName for fileName in os.listdir(subdir1) if 'tiff' not in fileName]        \n",
    "        \n",
    "        for n in tqdm(range(len(files_temp))):\n",
    "            file1 = files_temp[n]\n",
    "            for file2 in os.listdir(os.path.join(subdir1,file1)): \n",
    "                if 'Best_4' not in file2:\n",
    "                    excel_file = pd.read_excel(os.path.join(subdir1,file1,file2)) # step0: Read and split data\n",
    "                    y = np.array(excel_file['L0'].values,dtype=np.float).reshape(-1,1)                        # Target data\n",
    "                    excel_file.drop(['Unnamed: 0','idx','idy','L0'], axis=1,inplace=True)\n",
    "                    features = ['L'+str(i) for i in range(1,len(excel_file.columns)-3)]<\n",
    "                    X = excel_file.values                \n",
    "                    y = MinMaxScaler().fit_transform(y) # Data Normalization\n",
    "                    X = MinMaxScaler().fit_transform(X)\n",
    "                    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=seed) # Split data\n",
    "\n",
    "                    kfold_indexes = list(KFold(10,shuffle=True,random_state=seed).split(train_X)) # split training into Kfolds and shuffle            \n",
    "                    Nfeatures = train_X.shape[1]\n",
    "                    ############### Model with selected hyper-parameters w/o cv (get scores using all data) (n_jobs=1 : to ensure replicability) ###############\n",
    "                    if ml_model == 'ANN':                    \n",
    "                        model = ANN(build_fn=build_model, epochs=100, batch_size=10, verbose=0)  # create model \n",
    "                    elif ml_model == 'KNN':                    \n",
    "                        train_y = train_y.ravel() # flatten to 1d array # data is in a column format while it expected it in a row.\n",
    "                        model = KNN(n_neighbors=8, leaf_size=1, weights='distance')\n",
    "                    elif ml_model == 'RF':\n",
    "                        train_y = train_y.ravel() # flatten to 1d array # data is in a column format while it expected it in a row.\n",
    "                        model = RFR(n_estimators=500, max_features=int(len(features)/3.0), max_depth=25, random_state=seed)\n",
    "\n",
    "                    scores = cross_validate(model,train_X,train_y,cv=kfold_indexes,scoring=scoring,return_estimator=True)            \n",
    "                    avg_mse = np.mean(scores['test_mse'])                \n",
    "                    avg_r2 = np.mean(scores['test_r2'])  \n",
    "                    ############### Save Results ###############\n",
    "                    Model.append(ml_model)\n",
    "                    GF.append(gf_folder)\n",
    "                    DATE.append(file1[:4]+'-'+file1[4:6]+'-'+file1[6:])\n",
    "                    Nb_S2_used.append(int(file2[17:18]))\n",
    "                    mse.append(round(-avg_mse,4)) # the computed values are negative\n",
    "                    r2.append(round(avg_r2,4))    \n",
    "\n",
    "############### Export Results ###############                \n",
    "results = pd.DataFrame({'Model':Model,\n",
    "                        'Date':DATE,\n",
    "                        'Gapfilling':GF,\n",
    "                        'Nb_S2_used':Nb_S2_used,\n",
    "                        'mse':mse,\n",
    "                        'r2':r2\n",
    "                        })\n",
    "outputdir2 = os.path.join(maindir2,'10k_cvResults_all3Models.xlsx')\n",
    "results.to_excel(outputdir2, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select best learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T12:11:31.314335Z",
     "start_time": "2021-10-01T12:11:31.309350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selected model: RF\n",
    "# N°S2: 2\n",
    "\n",
    "# run the algorithm on all training data\n",
    "# check MSE and R2 are similar to previous\n",
    "# Get feature importance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-17T04:47:21.191203Z",
     "start_time": "2022-01-17T04:44:34.265880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [02:46<00:00, 11.10s/it]\n"
     ]
    }
   ],
   "source": [
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "maindir2 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning'\n",
    "ml_models = ['RF']\n",
    "# gf_folders = ['withoutGF', 'withGF']\n",
    "gf_folders = ['withGF']\n",
    "\n",
    "Model = []\n",
    "GF = []\n",
    "DATE = []\n",
    "Nb_S2_used = []\n",
    "mse = []\n",
    "r2 = []\n",
    "best3Features = []\n",
    "        \n",
    "for ml_model in ml_models:    \n",
    "    for gf_folder in gf_folders:    \n",
    "        subdir1 = os.path.join(maindir1,gf_folder,'France')\n",
    "        files_temp = [fileName for fileName in os.listdir(subdir1) if 'tiff' not in fileName]        \n",
    "        \n",
    "        for n in tqdm(range(len(files_temp))):\n",
    "            file1 = files_temp[n]\n",
    "            for file2 in os.listdir(os.path.join(subdir1,file1)): \n",
    "                if 'Best_2' in file2:\n",
    "                    excel_file = pd.read_excel(os.path.join(subdir1,file1,file2)) # step0: Read and split data\n",
    "                    y = np.array(excel_file['L0'].values,dtype=np.float).reshape(-1,1)                        # Target data\n",
    "                    excel_file.drop(['Unnamed: 0','idx','idy','L0'], axis=1,inplace=True)\n",
    "                    features = ['L'+str(i) for i in range(1,len(excel_file.columns)-3)]\n",
    "                    X = excel_file.values                \n",
    "                    y = MinMaxScaler().fit_transform(y) # Data Normalization\n",
    "                    X = MinMaxScaler().fit_transform(X)\n",
    "                    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=seed) # Split data\n",
    "\n",
    "                    Nfeatures = train_X.shape[1]\n",
    "                    train_y = train_y.ravel() # flatten to 1d array # data is in a column format while it expected it in a row.\n",
    "                    \n",
    "                    ############### Predict turbidity using RF ()###############\n",
    "                    model = RFR(n_estimators=500, max_features=int(len(features)/3.0), max_depth=10, random_state=seed)                    \n",
    "                    model.fit(train_X, train_y)\n",
    "                    y_pred = model.predict(val_X)\n",
    "                    \n",
    "                    importance = model.feature_importances_\n",
    "                    indices = sorted(range(len(importance)), key=lambda i: importance[i])[-3:]\n",
    "                    dict_temp = {'B':[1,10,19,28],'G':[4,13,22,31],'R':[7,16,25,34],\n",
    "                                 'BG':[2,11,20,29],'GB':[5,14,23,32],'RB':[8,17,26,35],\n",
    "                                 'BR':[3,12,21,30],'GR':[6,15,24,33],'RG':[9,18,27,36]}\n",
    "                    best3F = ''\n",
    "                    for i in indices:\n",
    "                        for key,values in dict_temp.items():\n",
    "                            if i+1 in values: # Add 1 because the indices were counted from 0 whilst layer names start from L1\n",
    "                                best3F+=key+' '\n",
    "                    \n",
    "                    Model.append(ml_model)\n",
    "                    GF.append(gf_folder)\n",
    "                    DATE.append(file1[:4]+'-'+file1[4:6]+'-'+file1[6:])\n",
    "                    Nb_S2_used.append(int(file2[17:18]))\n",
    "                    mse.append(round(mean_squared_error(val_y, y_pred, squared=True),4))\n",
    "                    r2.append(round(r2_score(val_y, y_pred),4)) \n",
    "                    best3Features.append(best3F)\n",
    "\n",
    "results = pd.DataFrame({'Model':Model,\n",
    "                        'Date':DATE,\n",
    "                        'Gapfilling':GF,\n",
    "                        'Nb_S2_used':Nb_S2_used,\n",
    "                        'mse':mse,\n",
    "                        'r2':r2,\n",
    "                        'best3Features':best3Features\n",
    "                        })\n",
    "\n",
    "# step7: Export as excel files\n",
    "outputdir2 = os.path.join(maindir2,'performanceResults_1Model.xlsx')\n",
    "results.to_excel(outputdir2, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T14:16:27.557130Z",
     "start_time": "2021-10-02T13:59:18.722682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [10:16<00:00, 41.13s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [06:50<00:00, 27.39s/it]\n"
     ]
    }
   ],
   "source": [
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "maindir2 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning'\n",
    "ml_models = ['RF']\n",
    "gf_folders = ['withoutGF', 'withGF']\n",
    "\n",
    "Model = []\n",
    "GF = []\n",
    "DATE = []\n",
    "Nb_S2_used = []\n",
    "mse = []\n",
    "r2 = []\n",
    "        \n",
    "for ml_model in ml_models:    \n",
    "    for gf_folder in gf_folders:    \n",
    "        subdir1 = os.path.join(maindir1,gf_folder,'France')\n",
    "        files_temp = [fileName for fileName in os.listdir(subdir1) if 'tiff' not in fileName]        \n",
    "        \n",
    "        for n in tqdm(range(len(files_temp))):\n",
    "            file1 = files_temp[n]\n",
    "            for file2 in os.listdir(os.path.join(subdir1,file1)): \n",
    "                if 'Best_2' in file2:\n",
    "                    excel_file = pd.read_excel(os.path.join(subdir1,file1,file2)) # step0: Read and split data\n",
    "                    y = np.array(excel_file['L0'].values,dtype=np.float).reshape(-1,1)                        # Target data\n",
    "                    excel_file.drop(['Unnamed: 0','idx','idy','L0'], axis=1,inplace=True)\n",
    "                    features = ['L'+str(i) for i in range(1,len(excel_file.columns)-3)]\n",
    "                    X = excel_file.values                \n",
    "                    y = MinMaxScaler().fit_transform(y) # Data Normalization\n",
    "                    X = MinMaxScaler().fit_transform(X)\n",
    "                    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=seed) # Split data\n",
    "\n",
    "                    Nfeatures = train_X.shape[1]\n",
    "                    \n",
    "                    ############### Predict turbidity using ANN ()###############\n",
    "                    model = ANN(build_fn=build_model, epochs=100, batch_size=10, verbose=0)  # create model                    \n",
    "                    model.fit(train_X, train_y)\n",
    "                    y_pred = model.predict(val_X)\n",
    "                    \n",
    "                    Model.append(ml_model)\n",
    "                    GF.append(gf_folder)\n",
    "                    DATE.append(file1[:4]+'-'+file1[4:6]+'-'+file1[6:])\n",
    "                    Nb_S2_used.append(int(file2[17:18]))\n",
    "                    mse.append(round(mean_squared_error(val_y, y_pred, squared=True),4))\n",
    "                    r2.append(round(r2_score(val_y, y_pred),4)) \n",
    "                    \n",
    "results = pd.DataFrame({'Model':Model,\n",
    "                        'Date':DATE,\n",
    "                        'Gapfilling':GF,\n",
    "                        'Nb_S2_used':Nb_S2_used,\n",
    "                        'mse':mse,\n",
    "                        'r2':r2\n",
    "                        })\n",
    "\n",
    "# step7: Export as excel files\n",
    "outputdir2 = os.path.join(maindir2,'perfANN.xlsx')\n",
    "results.to_excel(outputdir2, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T14:17:08.420840Z",
     "start_time": "2021-10-02T14:16:27.756629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:20<00:00,  1.34s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:20<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "maindir1 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning\\preparedInputData'\n",
    "maindir2 = r'G:\\MScThesis\\waterQualityMonitoring\\Data\\MLearning'\n",
    "ml_models = ['RF']\n",
    "gf_folders = ['withoutGF', 'withGF']\n",
    "\n",
    "Model = []\n",
    "GF = []\n",
    "DATE = []\n",
    "Nb_S2_used = []\n",
    "mse = []\n",
    "r2 = []\n",
    "        \n",
    "for ml_model in ml_models:    \n",
    "    for gf_folder in gf_folders:    \n",
    "        subdir1 = os.path.join(maindir1,gf_folder,'France')\n",
    "        files_temp = [fileName for fileName in os.listdir(subdir1) if 'tiff' not in fileName]        \n",
    "        \n",
    "        for n in tqdm(range(len(files_temp))):\n",
    "            file1 = files_temp[n]\n",
    "            for file2 in os.listdir(os.path.join(subdir1,file1)): \n",
    "                if 'Best_2' in file2:\n",
    "                    excel_file = pd.read_excel(os.path.join(subdir1,file1,file2)) # step0: Read and split data\n",
    "                    y = np.array(excel_file['L0'].values,dtype=np.float).reshape(-1,1)                        # Target data\n",
    "                    excel_file.drop(['Unnamed: 0','idx','idy','L0'], axis=1,inplace=True)\n",
    "                    features = ['L'+str(i) for i in range(1,len(excel_file.columns)-3)]\n",
    "                    X = excel_file.values                \n",
    "                    y = MinMaxScaler().fit_transform(y) # Data Normalization\n",
    "                    X = MinMaxScaler().fit_transform(X)\n",
    "                    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=seed) # Split data\n",
    "\n",
    "                    Nfeatures = train_X.shape[1]\n",
    "                    train_y = train_y.ravel() # flatten to 1d array # data is in a column format while it expected it in a row.\n",
    "                    \n",
    "                    ############### Predict turbidity using KNN ()###############\n",
    "                    model = KNN(n_neighbors=8, leaf_size=1, weights='distance')\n",
    "                    model.fit(train_X, train_y)\n",
    "                    y_pred = model.predict(val_X)\n",
    "                    \n",
    "                    Model.append(ml_model)\n",
    "                    GF.append(gf_folder)\n",
    "                    DATE.append(file1[:4]+'-'+file1[4:6]+'-'+file1[6:])\n",
    "                    Nb_S2_used.append(int(file2[17:18]))\n",
    "                    mse.append(round(mean_squared_error(val_y, y_pred, squared=True),4))\n",
    "                    r2.append(round(r2_score(val_y, y_pred),4)) \n",
    "                    \n",
    "results = pd.DataFrame({'Model':Model,\n",
    "                        'Date':DATE,\n",
    "                        'Gapfilling':GF,\n",
    "                        'Nb_S2_used':Nb_S2_used,\n",
    "                        'mse':mse,\n",
    "                        'r2':r2\n",
    "                        })\n",
    "\n",
    "# step7: Export as excel files\n",
    "outputdir2 = os.path.join(maindir2,'perfKNN.xlsx')\n",
    "results.to_excel(outputdir2, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
